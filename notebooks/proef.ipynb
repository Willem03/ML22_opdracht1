{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0, \"../..\")\n",
    "\n",
    "from typing import Callable, Protocol, Dict, Optional, Iterator, List, Tuple\n",
    "\n",
    "import gin\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "#from src.data import make_dataset\n",
    "#from src.models import metrics\n",
    "#from src.models import train_model # om de functie train_loop binnen te halen\n",
    "\n",
    "# ------------------------------------------------------------------------------- #\n",
    "## Alle imports benodigd voor de functie train_loop uit train_model.py \n",
    "\n",
    "import tensorflow as tf  # noqa: F401\n",
    "\n",
    "# needed to make summarywriter load without error\n",
    "from loguru import logger\n",
    "from numpy import Inf\n",
    "from ray import tune\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from src.models.metrics import Metric\n",
    "#from src.typehinting import GenericModel\n",
    "#from src.data import data_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## benodigde functie uitmake_dataset.py\n",
    "\n",
    "#@gin.configurable\n",
    "def get_MNIST(  # noqa: N802\n",
    "    data_dir: Path, batch_size: int\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benodigde funties uit metrics.py\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "class Metric:\n",
    "    def __repr__(self) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, y: Tensor, yhat: Tensor) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Accuracy(Metric):\n",
    "    def __repr__(self) -> str:\n",
    "        return \"Accuracy\"\n",
    "\n",
    "    def __call__(self, y: Tensor, yhat: Tensor) -> Tensor:\n",
    "        return (yhat.argmax(dim=1) == y).sum() / len(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericModel(Protocol):\n",
    "    train: Callable\n",
    "    eval: Callable\n",
    "    parameters: Callable\n",
    "\n",
    "    def __call__(self, *args, **kwargs) -> torch.Tensor:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: GenericModel) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uit data_tools.py\n",
    "\n",
    "def dir_add_timestamp(log_dir: Optional[Path] = None) -> Path:\n",
    "    if log_dir is None:\n",
    "        log_dir = Path(\".\")\n",
    "    log_dir = Path(log_dir)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    log_dir = log_dir / timestamp\n",
    "    logger.info(f\"Logging to {log_dir}\")\n",
    "    if not log_dir.exists():\n",
    "        log_dir.mkdir(parents=True)\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definieren functie train_loop\n",
    "\n",
    "#@gin.configurable\n",
    "def trainloop(\n",
    "    epochs: int,\n",
    "    model: GenericModel,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    learning_rate: float,\n",
    "    loss_fn: Callable,\n",
    "    metrics: List[Metric],\n",
    "    train_dataloader: Iterator,\n",
    "    test_dataloader: Iterator,\n",
    "    log_dir: Path,\n",
    "    train_steps: int,\n",
    "    eval_steps: int,\n",
    "    patience: int = 10,\n",
    "    factor: float = 0.9,\n",
    "    tunewriter: bool = False,\n",
    ") -> GenericModel:\n",
    "    \n",
    "    optimizer_: torch.optim.Optimizer = optimizer(\n",
    "        model.parameters(), lr=learning_rate\n",
    "    )  # type: ignore\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_,\n",
    "        factor=factor,\n",
    "        patience=patience,\n",
    "    )\n",
    "\n",
    "    if not tunewriter:\n",
    "        log_dir = dir_add_timestamp(log_dir)\n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "        #write_gin(log_dir, gin.config_str())\n",
    "\n",
    "        images, _ = next(iter(train_dataloader))\n",
    "        if len(images.shape) == 4:\n",
    "            grid = make_grid(images)\n",
    "            writer.add_image(\"images\", grid)\n",
    "        writer.add_graph(model, images)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = trainbatches(\n",
    "            model, train_dataloader, loss_fn, optimizer_, train_steps\n",
    "        )\n",
    "\n",
    "        metric_dict, test_loss = evalbatches(\n",
    "            model, test_dataloader, loss_fn, metrics, eval_steps\n",
    "        )\n",
    "\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "        if tunewriter:\n",
    "            tune.report(\n",
    "                iterations=epoch,\n",
    "                train_loss=train_loss,\n",
    "                test_loss=test_loss,\n",
    "                **metric_dict,\n",
    "            )\n",
    "        else:\n",
    "            writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "            writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "            for m in metric_dict:\n",
    "                writer.add_scalar(f\"metric/{m}\", metric_dict[m], epoch)\n",
    "            lr = [group[\"lr\"] for group in optimizer_.param_groups][0]\n",
    "            writer.add_scalar(\"learning_rate\", lr, epoch)\n",
    "            metric_scores = [f\"{v:.4f}\" for v in metric_dict.values()]\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch} train {train_loss:.4f} test {test_loss:.4f} metric {metric_scores}\"  # noqa E501\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uit train_model.py\n",
    "\n",
    "def trainbatches(\n",
    "    model: GenericModel,\n",
    "    traindatastreamer: Iterator,\n",
    "    loss_fn: Callable,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_steps: int,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    train_loss: float = 0.0\n",
    "    for _ in tqdm(range(train_steps)):\n",
    "        x, y = next(iter(traindatastreamer))\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.detach().numpy()\n",
    "    train_loss /= train_steps\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uit train_model.py\n",
    "\n",
    "def evalbatches(\n",
    "    model: GenericModel,\n",
    "    testdatastreamer: Iterator,\n",
    "    loss_fn: Callable,\n",
    "    metrics: List[Metric],\n",
    "    eval_steps: int,\n",
    ") -> Tuple[Dict[str, float], float]:\n",
    "    model.eval()\n",
    "    test_loss: float = 0.0\n",
    "    metric_dict: Dict[str, float] = {}\n",
    "    for _ in range(eval_steps):\n",
    "        x, y = next(iter(testdatastreamer))\n",
    "        yhat = model(x)\n",
    "        test_loss += loss_fn(yhat, y).detach().numpy()\n",
    "        for m in metrics:\n",
    "            metric_dict[str(m)] = (\n",
    "                metric_dict.get(str(m), 0.0) + m(y, yhat).detach().numpy()\n",
    "            )\n",
    "\n",
    "    test_loss /= eval_steps\n",
    "    for key in metric_dict:\n",
    "        metric_dict[str(key)] = metric_dict[str(key)] / eval_steps\n",
    "    return metric_dict, test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gin.parse_config_file(\"model.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 1: CNN_een met een convolutional layer & drie linear layers\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_een_drie(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6272, 3136),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3136, 1568),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1568, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_een_drie = CNN_een_drie(10, 3, 32, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.2: CNN_twee met twee convolutional layers & twee linear layers\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_twee_twee(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_twee_twee = CNN_twee_twee(10, 3, 32, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_twee_twee_channels_16_32             [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 32, 6, 6]            --\n",
      "│    └─Conv2d: 2-1                       [64, 16, 28, 28]          160\n",
      "│    └─ReLU: 2-2                         [64, 16, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 16, 14, 14]          --\n",
      "│    └─Conv2d: 2-4                       [64, 32, 12, 12]          4,640\n",
      "│    └─ReLU: 2-5                         [64, 32, 12, 12]          --\n",
      "│    └─MaxPool2d: 2-6                    [64, 32, 6, 6]            --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-7                      [64, 1152]                --\n",
      "│    └─Linear: 2-8                       [64, 576]                 664,128\n",
      "│    └─ReLU: 2-9                         [64, 576]                 --\n",
      "│    └─Linear: 2-10                      [64, 10]                  5,770\n",
      "==========================================================================================\n",
      "Total params: 674,698\n",
      "Trainable params: 674,698\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 93.66\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 9.08\n",
      "Params size (MB): 2.70\n",
      "Estimated Total Size (MB): 11.98\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "## Model 2.2: CNN_twee met twee convolutional layers & twee linear layers & 16-32 filters\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_twee_twee_channels_16_32(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_twee_twee_channels_16_32 = CNN_twee_twee_channels_16_32(10, 3, 16, 32).to(device)\n",
    "\n",
    "print(summary(model_twee_twee_channels_16_32, input_size=(64, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_twee_twee_channels_32_64             [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 64, 6, 6]            --\n",
      "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
      "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
      "│    └─Conv2d: 2-4                       [64, 64, 12, 12]          18,496\n",
      "│    └─ReLU: 2-5                         [64, 64, 12, 12]          --\n",
      "│    └─MaxPool2d: 2-6                    [64, 64, 6, 6]            --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-7                      [64, 2304]                --\n",
      "│    └─Linear: 2-8                       [64, 1152]                2,655,360\n",
      "│    └─ReLU: 2-9                         [64, 1152]                --\n",
      "│    └─Linear: 2-10                      [64, 10]                  11,530\n",
      "==========================================================================================\n",
      "Total params: 2,685,706\n",
      "Trainable params: 2,685,706\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 357.20\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 18.16\n",
      "Params size (MB): 10.74\n",
      "Estimated Total Size (MB): 29.10\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "## Model 2.2: CNN_twee met twee convolutional layers & twee linear layers & 32-64 filters\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_twee_twee_channels_32_64(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2304, 1152),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1152, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_twee_twee_channels_32_64 = CNN_twee_twee_channels_32_64(10, 3, 32, 64).to(device)\n",
    "\n",
    "print(summary(model_twee_twee_channels_32_64, input_size=(64, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.3: CNN_twee met twee convolutional layers en drie linear layers\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_twee_drie(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, 288),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(288, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_twee_drie = CNN_twee_drie(10, 3, 32, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_twee_drie_channels_16_32             [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 32, 6, 6]            --\n",
      "│    └─Conv2d: 2-1                       [64, 16, 28, 28]          160\n",
      "│    └─ReLU: 2-2                         [64, 16, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 16, 14, 14]          --\n",
      "│    └─Conv2d: 2-4                       [64, 32, 12, 12]          4,640\n",
      "│    └─ReLU: 2-5                         [64, 32, 12, 12]          --\n",
      "│    └─MaxPool2d: 2-6                    [64, 32, 6, 6]            --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-7                      [64, 1152]                --\n",
      "│    └─Linear: 2-8                       [64, 576]                 664,128\n",
      "│    └─ReLU: 2-9                         [64, 576]                 --\n",
      "│    └─Linear: 2-10                      [64, 288]                 166,176\n",
      "│    └─ReLU: 2-11                        [64, 288]                 --\n",
      "│    └─Linear: 2-12                      [64, 10]                  2,890\n",
      "==========================================================================================\n",
      "Total params: 837,994\n",
      "Trainable params: 837,994\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 104.11\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 9.23\n",
      "Params size (MB): 3.35\n",
      "Estimated Total Size (MB): 12.78\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "## Model 2.3: CNN_twee met twee convolutional layers en drie linear layers\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_twee_drie_channels_16_32(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, 288),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(288, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_twee_drie_channels_16_32 = CNN_twee_drie_channels_16_32(10, 3, 16, 32).to(device)\n",
    "\n",
    "print(summary(model_twee_drie_channels_16_32, input_size=(64, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_twee_drie_channels_32_64             [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 64, 6, 6]            --\n",
      "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
      "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
      "│    └─Conv2d: 2-4                       [64, 64, 12, 12]          18,496\n",
      "│    └─ReLU: 2-5                         [64, 64, 12, 12]          --\n",
      "│    └─MaxPool2d: 2-6                    [64, 64, 6, 6]            --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-7                      [64, 2304]                --\n",
      "│    └─Linear: 2-8                       [64, 1152]                2,655,360\n",
      "│    └─ReLU: 2-9                         [64, 1152]                --\n",
      "│    └─Linear: 2-10                      [64, 576]                 664,128\n",
      "│    └─ReLU: 2-11                        [64, 576]                 --\n",
      "│    └─Linear: 2-12                      [64, 10]                  5,770\n",
      "==========================================================================================\n",
      "Total params: 3,344,074\n",
      "Trainable params: 3,344,074\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 399.33\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 18.45\n",
      "Params size (MB): 13.38\n",
      "Estimated Total Size (MB): 32.03\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "## Model 2.3: CNN_twee met twee convolutional layers en drie linear layers\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_twee_drie_channels_32_64(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2304, 1152),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_twee_drie_channels_32_64 = CNN_twee_drie_channels_32_64(10, 3, 32, 64).to(device)\n",
    "\n",
    "print(summary(model_twee_drie_channels_32_64, input_size=(64, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.4: CNN_twee met twee convolutional layers & vier linear layers\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_twee_vier(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, 288),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(288, 144),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(144, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_twee_vier = CNN_twee_vier(10, 3, 32, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3.2: CNN_drie met twee convolutional layers & twee linear layers\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_drie_twee(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_drie_twee = CNN_drie_twee(10, 3, 32, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3.3: CNN_drie met drie convolutional layers\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_drie_drie(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_drie_drie = CNN_drie_drie(10, 3, 32, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3.4: CNN_drie met drie convolutional layers & vier linear layers\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_drie_vier(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "model_drie_vier = CNN_drie_vier(10, 3, 32, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "modellen = [\n",
    "            model_een_drie,\n",
    "            model_twee_twee,\n",
    "            model_twee_drie,\n",
    "            model_twee_vier,\n",
    "            model_drie_twee,\n",
    "            model_drie_drie,\n",
    "            model_drie_vier,\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_een_drie                             [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 32, 14, 14]          --\n",
      "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
      "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-4                      [64, 6272]                --\n",
      "│    └─Linear: 2-5                       [64, 3136]                19,672,128\n",
      "│    └─ReLU: 2-6                         [64, 3136]                --\n",
      "│    └─Linear: 2-7                       [64, 1568]                4,918,816\n",
      "│    └─ReLU: 2-8                         [64, 1568]                --\n",
      "│    └─Linear: 2-9                       [64, 10]                  15,690\n",
      "==========================================================================================\n",
      "Total params: 24,606,954\n",
      "Trainable params: 24,606,954\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.59\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 15.26\n",
      "Params size (MB): 98.43\n",
      "Estimated Total Size (MB): 113.89\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_twee_twee                            [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 32, 6, 6]            --\n",
      "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
      "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
      "│    └─Conv2d: 2-4                       [64, 32, 12, 12]          9,248\n",
      "│    └─ReLU: 2-5                         [64, 32, 12, 12]          --\n",
      "│    └─MaxPool2d: 2-6                    [64, 32, 6, 6]            --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-7                      [64, 1152]                --\n",
      "│    └─Linear: 2-8                       [64, 576]                 664,128\n",
      "│    └─ReLU: 2-9                         [64, 576]                 --\n",
      "│    └─Linear: 2-10                      [64, 10]                  5,770\n",
      "==========================================================================================\n",
      "Total params: 679,466\n",
      "Trainable params: 679,466\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 144.16\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 15.50\n",
      "Params size (MB): 2.72\n",
      "Estimated Total Size (MB): 18.42\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_twee_drie                            [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 32, 6, 6]            --\n",
      "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
      "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
      "│    └─Conv2d: 2-4                       [64, 32, 12, 12]          9,248\n",
      "│    └─ReLU: 2-5                         [64, 32, 12, 12]          --\n",
      "│    └─MaxPool2d: 2-6                    [64, 32, 6, 6]            --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-7                      [64, 1152]                --\n",
      "│    └─Linear: 2-8                       [64, 576]                 664,128\n",
      "│    └─ReLU: 2-9                         [64, 576]                 --\n",
      "│    └─Linear: 2-10                      [64, 288]                 166,176\n",
      "│    └─ReLU: 2-11                        [64, 288]                 --\n",
      "│    └─Linear: 2-12                      [64, 10]                  2,890\n",
      "==========================================================================================\n",
      "Total params: 842,762\n",
      "Trainable params: 842,762\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 154.61\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 15.65\n",
      "Params size (MB): 3.37\n",
      "Estimated Total Size (MB): 19.22\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_twee_vier                            [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 32, 6, 6]            --\n",
      "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
      "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
      "│    └─Conv2d: 2-4                       [64, 32, 12, 12]          9,248\n",
      "│    └─ReLU: 2-5                         [64, 32, 12, 12]          --\n",
      "│    └─MaxPool2d: 2-6                    [64, 32, 6, 6]            --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-7                      [64, 1152]                --\n",
      "│    └─Linear: 2-8                       [64, 576]                 664,128\n",
      "│    └─ReLU: 2-9                         [64, 576]                 --\n",
      "│    └─Linear: 2-10                      [64, 288]                 166,176\n",
      "│    └─ReLU: 2-11                        [64, 288]                 --\n",
      "│    └─Linear: 2-12                      [64, 144]                 41,616\n",
      "│    └─ReLU: 2-13                        [64, 144]                 --\n",
      "│    └─Linear: 2-14                      [64, 10]                  1,450\n",
      "==========================================================================================\n",
      "Total params: 882,938\n",
      "Trainable params: 882,938\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 157.18\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 15.73\n",
      "Params size (MB): 3.53\n",
      "Estimated Total Size (MB): 19.46\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_drie_twee                            [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 32, 2, 2]            --\n",
      "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
      "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
      "│    └─Conv2d: 2-4                       [64, 32, 12, 12]          9,248\n",
      "│    └─ReLU: 2-5                         [64, 32, 12, 12]          --\n",
      "│    └─MaxPool2d: 2-6                    [64, 32, 6, 6]            --\n",
      "│    └─Conv2d: 2-7                       [64, 32, 4, 4]            9,248\n",
      "│    └─ReLU: 2-8                         [64, 32, 4, 4]            --\n",
      "│    └─MaxPool2d: 2-9                    [64, 32, 2, 2]            --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-10                     [64, 128]                 --\n",
      "│    └─Linear: 2-11                      [64, 64]                  8,256\n",
      "│    └─ReLU: 2-12                        [64, 64]                  --\n",
      "│    └─Linear: 2-13                      [64, 10]                  650\n",
      "==========================================================================================\n",
      "Total params: 27,722\n",
      "Trainable params: 27,722\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 111.33\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 15.50\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 15.82\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_drie_drie                            [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 32, 2, 2]            --\n",
      "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
      "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
      "│    └─Conv2d: 2-4                       [64, 32, 12, 12]          9,248\n",
      "│    └─ReLU: 2-5                         [64, 32, 12, 12]          --\n",
      "│    └─MaxPool2d: 2-6                    [64, 32, 6, 6]            --\n",
      "│    └─Conv2d: 2-7                       [64, 32, 4, 4]            9,248\n",
      "│    └─ReLU: 2-8                         [64, 32, 4, 4]            --\n",
      "│    └─MaxPool2d: 2-9                    [64, 32, 2, 2]            --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-10                     [64, 128]                 --\n",
      "│    └─Linear: 2-11                      [64, 64]                  8,256\n",
      "│    └─ReLU: 2-12                        [64, 64]                  --\n",
      "│    └─Linear: 2-13                      [64, 32]                  2,080\n",
      "│    └─ReLU: 2-14                        [64, 32]                  --\n",
      "│    └─Linear: 2-15                      [64, 10]                  330\n",
      "==========================================================================================\n",
      "Total params: 29,482\n",
      "Trainable params: 29,482\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 111.44\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 15.52\n",
      "Params size (MB): 0.12\n",
      "Estimated Total Size (MB): 15.84\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_drie_vier                            [64, 10]                  --\n",
      "├─Sequential: 1-1                        [64, 32, 2, 2]            --\n",
      "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
      "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
      "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
      "│    └─Conv2d: 2-4                       [64, 32, 12, 12]          9,248\n",
      "│    └─ReLU: 2-5                         [64, 32, 12, 12]          --\n",
      "│    └─MaxPool2d: 2-6                    [64, 32, 6, 6]            --\n",
      "│    └─Conv2d: 2-7                       [64, 32, 4, 4]            9,248\n",
      "│    └─ReLU: 2-8                         [64, 32, 4, 4]            --\n",
      "│    └─MaxPool2d: 2-9                    [64, 32, 2, 2]            --\n",
      "├─Sequential: 1-2                        [64, 10]                  --\n",
      "│    └─Flatten: 2-10                     [64, 128]                 --\n",
      "│    └─Linear: 2-11                      [64, 64]                  8,256\n",
      "│    └─ReLU: 2-12                        [64, 64]                  --\n",
      "│    └─Linear: 2-13                      [64, 32]                  2,080\n",
      "│    └─ReLU: 2-14                        [64, 32]                  --\n",
      "│    └─Linear: 2-15                      [64, 10]                  330\n",
      "==========================================================================================\n",
      "Total params: 29,482\n",
      "Trainable params: 29,482\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 111.44\n",
      "==========================================================================================\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 15.52\n",
      "Params size (MB): 0.12\n",
      "Estimated Total Size (MB): 15.84\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "for model in modellen:\n",
    "    print(summary(model, input_size=(64, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"model.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938, 157)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir =  Path(\"/home/admindme/code/ML22_opdracht1/data/raw/FashionMNIST\")\n",
    "train_dataloader, test_dataloader = get_MNIST(datadir, 64)\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 13:32:30.559 | INFO     | __main__:dir_add_timestamp:9 - Logging to ../../models/test/20221218-1332\n",
      "100%|██████████| 938/938 [00:41<00:00, 22.82it/s]\n",
      "2022-12-18 13:33:14.581 | INFO     | __main__:trainloop:68 - Epoch 0 train 0.1789 test 0.2868 metric ['0.8984']\n",
      "100%|██████████| 938/938 [00:41<00:00, 22.63it/s]\n",
      "2022-12-18 13:33:58.779 | INFO     | __main__:trainloop:68 - Epoch 1 train 0.1514 test 0.2516 metric ['0.9153']\n",
      "100%|██████████| 938/938 [00:41<00:00, 22.55it/s]\n",
      "2022-12-18 13:34:43.057 | INFO     | __main__:trainloop:68 - Epoch 2 train 0.1248 test 0.2642 metric ['0.9181']\n",
      "100%|██████████| 938/938 [00:41<00:00, 22.39it/s]\n",
      "2022-12-18 13:35:27.658 | INFO     | __main__:trainloop:68 - Epoch 3 train 0.1048 test 0.2622 metric ['0.9139']\n",
      "100%|██████████| 938/938 [00:42<00:00, 22.25it/s]\n",
      "2022-12-18 13:36:12.545 | INFO     | __main__:trainloop:68 - Epoch 4 train 0.0835 test 0.2512 metric ['0.9273']\n",
      "100%|██████████| 938/938 [00:42<00:00, 22.14it/s]\n",
      "2022-12-18 13:36:57.662 | INFO     | __main__:trainloop:68 - Epoch 5 train 0.0700 test 0.3003 metric ['0.9163']\n",
      "100%|██████████| 938/938 [00:42<00:00, 21.93it/s]\n",
      "2022-12-18 13:37:43.145 | INFO     | __main__:trainloop:68 - Epoch 6 train 0.0579 test 0.3388 metric ['0.9125']\n",
      "100%|██████████| 938/938 [00:42<00:00, 22.15it/s]\n",
      "2022-12-18 13:38:28.161 | INFO     | __main__:trainloop:68 - Epoch 7 train 0.0498 test 0.3063 metric ['0.9218']\n",
      "100%|██████████| 938/938 [00:42<00:00, 22.07it/s]\n",
      "2022-12-18 13:39:13.470 | INFO     | __main__:trainloop:68 - Epoch 8 train 0.0419 test 0.3852 metric ['0.9168']\n",
      "100%|██████████| 938/938 [00:42<00:00, 22.06it/s]\n",
      "2022-12-18 13:39:58.676 | INFO     | __main__:trainloop:68 - Epoch 9 train 0.0329 test 0.3664 metric ['0.9192']\n",
      "100%|██████████| 938/938 [00:42<00:00, 21.82it/s]\n",
      "2022-12-18 13:40:44.355 | INFO     | __main__:trainloop:68 - Epoch 10 train 0.0286 test 0.3929 metric ['0.9146']\n",
      "100%|██████████| 938/938 [00:42<00:00, 21.90it/s]\n",
      "2022-12-18 13:41:29.867 | INFO     | __main__:trainloop:68 - Epoch 11 train 0.0258 test 0.3757 metric ['0.9248']\n",
      "100%|██████████| 938/938 [00:42<00:00, 21.86it/s]\n",
      "2022-12-18 13:42:15.421 | INFO     | __main__:trainloop:68 - Epoch 12 train 0.0220 test 0.3964 metric ['0.9202']\n",
      "100%|██████████| 938/938 [00:42<00:00, 21.94it/s]\n",
      "2022-12-18 13:43:00.885 | INFO     | __main__:trainloop:68 - Epoch 13 train 0.0229 test 0.4116 metric ['0.9241']\n",
      "100%|██████████| 938/938 [00:42<00:00, 21.94it/s]\n",
      "2022-12-18 13:43:46.293 | INFO     | __main__:trainloop:68 - Epoch 14 train 0.0192 test 0.4531 metric ['0.9205']\n",
      "100%|██████████| 938/938 [00:42<00:00, 21.84it/s]\n",
      "2022-12-18 13:44:31.938 | INFO     | __main__:trainloop:68 - Epoch 15 train 0.0173 test 0.4670 metric ['0.9164']\n",
      "100%|██████████| 938/938 [00:43<00:00, 21.68it/s]\n",
      "2022-12-18 13:45:17.863 | INFO     | __main__:trainloop:68 - Epoch 16 train 0.0130 test 0.4776 metric ['0.9163']\n",
      "100%|██████████| 938/938 [00:43<00:00, 21.57it/s]\n",
      "2022-12-18 13:46:04.095 | INFO     | __main__:trainloop:68 - Epoch 17 train 0.0114 test 0.4410 metric ['0.9246']\n",
      "100%|██████████| 938/938 [00:44<00:00, 21.30it/s]\n",
      "2022-12-18 13:46:50.895 | INFO     | __main__:trainloop:68 - Epoch 18 train 0.0115 test 0.5797 metric ['0.9180']\n",
      "100%|██████████| 938/938 [00:44<00:00, 21.05it/s]\n",
      "2022-12-18 13:47:38.118 | INFO     | __main__:trainloop:68 - Epoch 19 train 0.0123 test 0.5637 metric ['0.9149']\n",
      "100%|██████████| 938/938 [00:44<00:00, 20.90it/s]\n",
      "2022-12-18 13:48:25.672 | INFO     | __main__:trainloop:68 - Epoch 20 train 0.0085 test 0.5376 metric ['0.9216']\n",
      "100%|██████████| 938/938 [00:44<00:00, 21.06it/s]\n",
      "2022-12-18 13:49:12.899 | INFO     | __main__:trainloop:68 - Epoch 21 train 0.0119 test 0.5685 metric ['0.9155']\n",
      "100%|██████████| 938/938 [00:46<00:00, 20.10it/s]\n",
      "2022-12-18 13:50:02.232 | INFO     | __main__:trainloop:68 - Epoch 22 train 0.0088 test 0.5741 metric ['0.9200']\n",
      "100%|██████████| 938/938 [00:48<00:00, 19.19it/s]\n",
      "2022-12-18 13:50:53.767 | INFO     | __main__:trainloop:68 - Epoch 23 train 0.0119 test 0.5683 metric ['0.9193']\n",
      "100%|██████████| 938/938 [00:50<00:00, 18.68it/s]\n",
      "2022-12-18 13:51:46.691 | INFO     | __main__:trainloop:68 - Epoch 24 train 0.0085 test 0.6332 metric ['0.9158']\n",
      "100%|██████████| 938/938 [00:51<00:00, 18.18it/s]\n",
      "2022-12-18 13:52:40.902 | INFO     | __main__:trainloop:68 - Epoch 25 train 0.0087 test 0.5345 metric ['0.9232']\n",
      "100%|██████████| 938/938 [00:50<00:00, 18.48it/s]\n",
      "2022-12-18 13:53:34.258 | INFO     | __main__:trainloop:68 - Epoch 26 train 0.0102 test 0.5409 metric ['0.9181']\n",
      "100%|██████████| 938/938 [00:49<00:00, 19.14it/s]\n",
      "2022-12-18 13:54:25.885 | INFO     | __main__:trainloop:68 - Epoch 27 train 0.0072 test 0.6302 metric ['0.9139']\n",
      "100%|██████████| 938/938 [00:50<00:00, 18.52it/s]\n",
      "2022-12-18 13:55:19.182 | INFO     | __main__:trainloop:68 - Epoch 28 train 0.0064 test 0.7188 metric ['0.9190']\n",
      "100%|██████████| 938/938 [00:52<00:00, 17.88it/s]\n",
      "2022-12-18 13:56:14.318 | INFO     | __main__:trainloop:68 - Epoch 29 train 0.0063 test 0.6620 metric ['0.9263']\n",
      "100%|██████████| 938/938 [00:51<00:00, 18.18it/s]\n",
      "2022-12-18 13:57:08.642 | INFO     | __main__:trainloop:68 - Epoch 30 train 0.0078 test 0.6589 metric ['0.9220']\n",
      "100%|██████████| 938/938 [00:52<00:00, 17.91it/s]\n",
      "2022-12-18 13:58:03.715 | INFO     | __main__:trainloop:68 - Epoch 31 train 0.0096 test 0.7192 metric ['0.9146']\n",
      "100%|██████████| 938/938 [00:53<00:00, 17.49it/s]\n",
      "2022-12-18 13:58:59.987 | INFO     | __main__:trainloop:68 - Epoch 32 train 0.0039 test 0.6452 metric ['0.9196']\n",
      "100%|██████████| 938/938 [00:53<00:00, 17.38it/s]\n",
      "2022-12-18 13:59:56.618 | INFO     | __main__:trainloop:68 - Epoch 33 train 0.0057 test 0.7518 metric ['0.9182']\n",
      "100%|██████████| 938/938 [00:54<00:00, 17.25it/s]\n",
      "2022-12-18 14:00:53.614 | INFO     | __main__:trainloop:68 - Epoch 34 train 0.0076 test 0.6755 metric ['0.9233']\n",
      "100%|██████████| 938/938 [00:56<00:00, 16.54it/s]\n",
      "2022-12-18 14:01:53.001 | INFO     | __main__:trainloop:68 - Epoch 35 train 0.0037 test 0.7357 metric ['0.9192']\n",
      "100%|██████████| 938/938 [00:56<00:00, 16.74it/s]\n",
      "2022-12-18 14:02:51.703 | INFO     | __main__:trainloop:68 - Epoch 36 train 0.0069 test 0.6665 metric ['0.9214']\n",
      "100%|██████████| 938/938 [00:55<00:00, 16.89it/s]\n",
      "2022-12-18 14:03:49.941 | INFO     | __main__:trainloop:68 - Epoch 37 train 0.0054 test 0.7992 metric ['0.9151']\n",
      "100%|██████████| 938/938 [00:56<00:00, 16.63it/s]\n",
      "2022-12-18 14:04:49.090 | INFO     | __main__:trainloop:68 - Epoch 38 train 0.0076 test 0.7105 metric ['0.9196']\n",
      "100%|██████████| 938/938 [00:57<00:00, 16.39it/s]\n",
      "2022-12-18 14:05:48.999 | INFO     | __main__:trainloop:68 - Epoch 39 train 0.0024 test 0.7092 metric ['0.9232']\n",
      "100%|██████████| 938/938 [00:57<00:00, 16.29it/s]\n",
      "2022-12-18 14:06:49.305 | INFO     | __main__:trainloop:68 - Epoch 40 train 0.0009 test 0.7324 metric ['0.9244']\n",
      "100%|██████████| 938/938 [00:58<00:00, 16.11it/s]\n",
      "2022-12-18 14:07:50.254 | INFO     | __main__:trainloop:68 - Epoch 41 train 0.0107 test 0.7708 metric ['0.9185']\n",
      "100%|██████████| 938/938 [00:58<00:00, 16.09it/s]\n",
      "2022-12-18 14:08:51.163 | INFO     | __main__:trainloop:68 - Epoch 42 train 0.0033 test 0.6841 metric ['0.9240']\n",
      "100%|██████████| 938/938 [00:59<00:00, 15.79it/s]\n",
      "2022-12-18 14:09:53.221 | INFO     | __main__:trainloop:68 - Epoch 43 train 0.0058 test 0.7620 metric ['0.9177']\n",
      "100%|██████████| 938/938 [00:59<00:00, 15.66it/s]\n",
      "2022-12-18 14:10:55.867 | INFO     | __main__:trainloop:68 - Epoch 44 train 0.0047 test 0.7936 metric ['0.9243']\n",
      "100%|██████████| 938/938 [01:00<00:00, 15.55it/s]\n",
      "2022-12-18 14:11:58.840 | INFO     | __main__:trainloop:68 - Epoch 45 train 0.0039 test 0.8398 metric ['0.9175']\n",
      "100%|██████████| 938/938 [01:00<00:00, 15.59it/s]\n",
      "2022-12-18 14:13:01.688 | INFO     | __main__:trainloop:68 - Epoch 46 train 0.0042 test 0.7339 metric ['0.9248']\n",
      "100%|██████████| 938/938 [01:00<00:00, 15.56it/s]\n",
      "2022-12-18 14:14:04.610 | INFO     | __main__:trainloop:68 - Epoch 47 train 0.0039 test 0.8361 metric ['0.9165']\n",
      "100%|██████████| 938/938 [00:59<00:00, 15.78it/s]\n",
      "2022-12-18 14:15:06.779 | INFO     | __main__:trainloop:68 - Epoch 48 train 0.0053 test 0.7512 metric ['0.9191']\n",
      "100%|██████████| 938/938 [01:01<00:00, 15.36it/s]\n",
      "2022-12-18 14:16:10.477 | INFO     | __main__:trainloop:68 - Epoch 49 train 0.0011 test 0.7099 metric ['0.9235']\n",
      "100%|██████████| 50/50 [43:39<00:00, 52.40s/it]\n",
      "2022-12-18 14:16:10.481 | INFO     | __main__:dir_add_timestamp:9 - Logging to ../../models/test/20221218-1416\n",
      "100%|██████████| 938/938 [00:27<00:00, 34.55it/s]\n",
      "2022-12-18 14:16:40.128 | INFO     | __main__:trainloop:68 - Epoch 0 train 0.1302 test 0.2709 metric ['0.9169']\n",
      "100%|██████████| 938/938 [00:27<00:00, 33.97it/s]\n",
      "2022-12-18 14:17:10.112 | INFO     | __main__:trainloop:68 - Epoch 1 train 0.1155 test 0.2889 metric ['0.9129']\n",
      "100%|██████████| 938/938 [00:27<00:00, 34.16it/s]\n",
      "2022-12-18 14:17:39.984 | INFO     | __main__:trainloop:68 - Epoch 2 train 0.0941 test 0.3019 metric ['0.9173']\n",
      "100%|██████████| 938/938 [00:27<00:00, 34.08it/s]\n",
      "2022-12-18 14:18:09.858 | INFO     | __main__:trainloop:68 - Epoch 3 train 0.0840 test 0.2961 metric ['0.9229']\n",
      "100%|██████████| 938/938 [00:27<00:00, 34.06it/s]\n",
      "2022-12-18 14:18:39.683 | INFO     | __main__:trainloop:68 - Epoch 4 train 0.0705 test 0.3240 metric ['0.9132']\n",
      "100%|██████████| 938/938 [00:27<00:00, 34.06it/s]\n",
      "2022-12-18 14:19:09.600 | INFO     | __main__:trainloop:68 - Epoch 5 train 0.0637 test 0.3885 metric ['0.9103']\n",
      "100%|██████████| 938/938 [00:27<00:00, 34.19it/s]\n",
      "2022-12-18 14:19:39.354 | INFO     | __main__:trainloop:68 - Epoch 6 train 0.0569 test 0.3981 metric ['0.9116']\n",
      "100%|██████████| 938/938 [00:27<00:00, 33.97it/s]\n",
      "2022-12-18 14:20:09.295 | INFO     | __main__:trainloop:68 - Epoch 7 train 0.0510 test 0.4199 metric ['0.9131']\n",
      "100%|██████████| 938/938 [00:27<00:00, 33.61it/s]\n",
      "2022-12-18 14:20:39.502 | INFO     | __main__:trainloop:68 - Epoch 8 train 0.0425 test 0.4346 metric ['0.9167']\n",
      "100%|██████████| 938/938 [00:27<00:00, 33.69it/s]\n",
      "2022-12-18 14:21:09.703 | INFO     | __main__:trainloop:68 - Epoch 9 train 0.0406 test 0.4897 metric ['0.9103']\n",
      "100%|██████████| 938/938 [00:27<00:00, 33.64it/s]\n",
      "2022-12-18 14:21:39.928 | INFO     | __main__:trainloop:68 - Epoch 10 train 0.0343 test 0.4437 metric ['0.9197']\n",
      "100%|██████████| 938/938 [00:28<00:00, 33.26it/s]\n",
      "2022-12-18 14:22:10.443 | INFO     | __main__:trainloop:68 - Epoch 11 train 0.0334 test 0.4715 metric ['0.9106']\n",
      "100%|██████████| 938/938 [00:28<00:00, 32.98it/s]\n",
      "2022-12-18 14:22:41.213 | INFO     | __main__:trainloop:68 - Epoch 12 train 0.0265 test 0.5219 metric ['0.9203']\n",
      "100%|██████████| 938/938 [00:28<00:00, 32.61it/s]\n",
      "2022-12-18 14:23:12.200 | INFO     | __main__:trainloop:68 - Epoch 13 train 0.0231 test 0.5480 metric ['0.9132']\n",
      "100%|██████████| 938/938 [00:28<00:00, 32.40it/s]\n",
      "2022-12-18 14:23:43.543 | INFO     | __main__:trainloop:68 - Epoch 14 train 0.0218 test 0.5438 metric ['0.9127']\n",
      "100%|██████████| 938/938 [00:29<00:00, 32.14it/s]\n",
      "2022-12-18 14:24:15.063 | INFO     | __main__:trainloop:68 - Epoch 15 train 0.0217 test 0.6132 metric ['0.9113']\n",
      "100%|██████████| 938/938 [00:29<00:00, 32.33it/s]\n",
      "2022-12-18 14:24:46.463 | INFO     | __main__:trainloop:68 - Epoch 16 train 0.0219 test 0.5592 metric ['0.9124']\n",
      "100%|██████████| 938/938 [00:30<00:00, 30.82it/s]\n",
      "2022-12-18 14:25:19.254 | INFO     | __main__:trainloop:68 - Epoch 17 train 0.0185 test 0.6154 metric ['0.9107']\n",
      "100%|██████████| 938/938 [00:30<00:00, 30.49it/s]\n",
      "2022-12-18 14:25:52.356 | INFO     | __main__:trainloop:68 - Epoch 18 train 0.0184 test 0.5995 metric ['0.9215']\n",
      "100%|██████████| 938/938 [00:31<00:00, 30.02it/s]\n",
      "2022-12-18 14:26:25.940 | INFO     | __main__:trainloop:68 - Epoch 19 train 0.0167 test 0.6965 metric ['0.9074']\n",
      "100%|██████████| 938/938 [00:31<00:00, 30.23it/s]\n",
      "2022-12-18 14:26:59.369 | INFO     | __main__:trainloop:68 - Epoch 20 train 0.0173 test 0.5587 metric ['0.9241']\n",
      "100%|██████████| 938/938 [00:31<00:00, 30.13it/s]\n",
      "2022-12-18 14:27:32.804 | INFO     | __main__:trainloop:68 - Epoch 21 train 0.0147 test 0.6083 metric ['0.9146']\n",
      "100%|██████████| 938/938 [00:31<00:00, 30.17it/s]\n",
      "2022-12-18 14:28:06.288 | INFO     | __main__:trainloop:68 - Epoch 22 train 0.0169 test 0.6858 metric ['0.9075']\n",
      "100%|██████████| 938/938 [00:31<00:00, 29.62it/s]\n",
      "2022-12-18 14:28:40.289 | INFO     | __main__:trainloop:68 - Epoch 23 train 0.0102 test 0.6165 metric ['0.9197']\n",
      "100%|██████████| 938/938 [00:30<00:00, 30.34it/s]\n",
      "2022-12-18 14:29:13.531 | INFO     | __main__:trainloop:68 - Epoch 24 train 0.0116 test 0.6952 metric ['0.9122']\n",
      "100%|██████████| 938/938 [00:31<00:00, 29.82it/s]\n",
      "2022-12-18 14:29:47.414 | INFO     | __main__:trainloop:68 - Epoch 25 train 0.0108 test 0.6362 metric ['0.9202']\n",
      "100%|██████████| 938/938 [00:32<00:00, 28.85it/s]\n",
      "2022-12-18 14:30:22.143 | INFO     | __main__:trainloop:68 - Epoch 26 train 0.0110 test 0.6369 metric ['0.9209']\n",
      "100%|██████████| 938/938 [00:32<00:00, 28.65it/s]\n",
      "2022-12-18 14:30:57.169 | INFO     | __main__:trainloop:68 - Epoch 27 train 0.0118 test 0.8048 metric ['0.9100']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.54it/s]\n",
      "2022-12-18 14:31:33.608 | INFO     | __main__:trainloop:68 - Epoch 28 train 0.0107 test 0.6847 metric ['0.9202']\n",
      "100%|██████████| 938/938 [00:33<00:00, 27.66it/s]\n",
      "2022-12-18 14:32:09.808 | INFO     | __main__:trainloop:68 - Epoch 29 train 0.0117 test 0.6519 metric ['0.9231']\n",
      "100%|██████████| 938/938 [00:32<00:00, 28.68it/s]\n",
      "2022-12-18 14:32:44.957 | INFO     | __main__:trainloop:68 - Epoch 30 train 0.0103 test 0.7064 metric ['0.9145']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.45it/s]\n",
      "2022-12-18 14:33:21.447 | INFO     | __main__:trainloop:68 - Epoch 31 train 0.0076 test 0.7712 metric ['0.9111']\n",
      "100%|██████████| 938/938 [00:33<00:00, 27.95it/s]\n",
      "2022-12-18 14:33:57.469 | INFO     | __main__:trainloop:68 - Epoch 32 train 0.0107 test 0.6679 metric ['0.9169']\n",
      "100%|██████████| 938/938 [00:33<00:00, 28.31it/s]\n",
      "2022-12-18 14:34:32.977 | INFO     | __main__:trainloop:68 - Epoch 33 train 0.0114 test 0.7725 metric ['0.9111']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.39it/s]\n",
      "2022-12-18 14:35:09.547 | INFO     | __main__:trainloop:68 - Epoch 34 train 0.0051 test 0.7826 metric ['0.9131']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.27it/s]\n",
      "2022-12-18 14:35:46.324 | INFO     | __main__:trainloop:68 - Epoch 35 train 0.0048 test 0.8385 metric ['0.9116']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.43it/s]\n",
      "2022-12-18 14:36:22.794 | INFO     | __main__:trainloop:68 - Epoch 36 train 0.0096 test 0.7306 metric ['0.9189']\n",
      "100%|██████████| 938/938 [00:33<00:00, 27.64it/s]\n",
      "2022-12-18 14:36:58.969 | INFO     | __main__:trainloop:68 - Epoch 37 train 0.0082 test 0.7670 metric ['0.9155']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.33it/s]\n",
      "2022-12-18 14:37:35.655 | INFO     | __main__:trainloop:68 - Epoch 38 train 0.0073 test 0.8226 metric ['0.9165']\n",
      "100%|██████████| 938/938 [00:34<00:00, 26.93it/s]\n",
      "2022-12-18 14:38:12.859 | INFO     | __main__:trainloop:68 - Epoch 39 train 0.0055 test 0.8296 metric ['0.9155']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.19it/s]\n",
      "2022-12-18 14:38:49.707 | INFO     | __main__:trainloop:68 - Epoch 40 train 0.0088 test 0.7582 metric ['0.9187']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.22it/s]\n",
      "2022-12-18 14:39:26.581 | INFO     | __main__:trainloop:68 - Epoch 41 train 0.0074 test 0.8714 metric ['0.9097']\n",
      "100%|██████████| 938/938 [00:35<00:00, 26.56it/s]\n",
      "2022-12-18 14:40:04.168 | INFO     | __main__:trainloop:68 - Epoch 42 train 0.0053 test 0.8442 metric ['0.9195']\n",
      "100%|██████████| 938/938 [00:34<00:00, 26.83it/s]\n",
      "2022-12-18 14:40:41.339 | INFO     | __main__:trainloop:68 - Epoch 43 train 0.0082 test 0.9191 metric ['0.9083']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.51it/s]\n",
      "2022-12-18 14:41:17.731 | INFO     | __main__:trainloop:68 - Epoch 44 train 0.0068 test 0.7639 metric ['0.9127']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.51it/s]\n",
      "2022-12-18 14:41:54.251 | INFO     | __main__:trainloop:68 - Epoch 45 train 0.0042 test 0.8015 metric ['0.9148']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.58it/s]\n",
      "2022-12-18 14:42:30.588 | INFO     | __main__:trainloop:68 - Epoch 46 train 0.0041 test 0.8917 metric ['0.9115']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.31it/s]\n",
      "2022-12-18 14:43:07.280 | INFO     | __main__:trainloop:68 - Epoch 47 train 0.0050 test 0.8525 metric ['0.9130']\n",
      "100%|██████████| 938/938 [00:34<00:00, 27.04it/s]\n",
      "2022-12-18 14:43:44.230 | INFO     | __main__:trainloop:68 - Epoch 48 train 0.0072 test 0.9286 metric ['0.9127']\n",
      "100%|██████████| 938/938 [00:34<00:00, 26.86it/s]\n",
      "2022-12-18 14:44:21.411 | INFO     | __main__:trainloop:68 - Epoch 49 train 0.0032 test 0.9016 metric ['0.9177']\n",
      "100%|██████████| 50/50 [28:10<00:00, 33.82s/it]\n"
     ]
    }
   ],
   "source": [
    "#models = [model_twee_twee, model_twee_vier, model_drie_twee, model_drie_vier]\n",
    "#models = [model_twee_twee, model_drie_twee]\n",
    "\n",
    "models = [model_twee_twee_channels_32_64, model_twee_drie_16_32]\n",
    "\n",
    "epochs = 50\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = Accuracy()\n",
    "\n",
    "for model in models:\n",
    "    model = trainloop(\n",
    "                epochs=epochs,\n",
    "                model=model,\n",
    "                optimizer=torch.optim.Adam,\n",
    "                learning_rate= 0.001,\n",
    "                loss_fn=loss_fn,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                log_dir=\"../../models/test/\",\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                #patience= ,\n",
    "                #factor= ,\n",
    "                #tunewriter= ,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 13:10:47.276 | INFO     | __main__:dir_add_timestamp:9 - Logging to ../../models/test/20221218-1310\n",
      "100%|██████████| 938/938 [00:29<00:00, 31.94it/s]\n",
      "2022-12-18 13:11:19.136 | INFO     | __main__:trainloop:68 - Epoch 0 train 0.2058 test 0.2545 metric ['0.9094']\n",
      "100%|██████████| 938/938 [00:29<00:00, 31.58it/s]\n",
      "2022-12-18 13:11:51.229 | INFO     | __main__:trainloop:68 - Epoch 1 train 0.1761 test 0.2759 metric ['0.9067']\n",
      "100%|██████████| 938/938 [00:29<00:00, 31.32it/s]\n",
      "2022-12-18 13:12:23.521 | INFO     | __main__:trainloop:68 - Epoch 2 train 0.1493 test 0.2597 metric ['0.9144']\n",
      "100%|██████████| 3/3 [01:36<00:00, 32.03s/it]\n"
     ]
    }
   ],
   "source": [
    "#model = model_een_drie\n",
    "#model = model_twee_twee_channels_16_32\n",
    "#model = model_twee_twee_channels_32_64\n",
    "model = model_twee_drie_16_32\n",
    "#model = model_twee_drie_32_64\n",
    "\n",
    "epochs = 3\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = Accuracy()\n",
    "\n",
    "model = trainloop(\n",
    "            epochs=epochs,\n",
    "            model=model,\n",
    "            optimizer=torch.optim.Adam,\n",
    "            learning_rate= 0.001,\n",
    "            loss_fn=loss_fn,\n",
    "            metrics=[accuracy],\n",
    "            train_dataloader=train_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            log_dir=\"../../models/test/\",\n",
    "            train_steps=len(train_dataloader),\n",
    "            eval_steps=150,\n",
    "            #patience= ,\n",
    "            #factor= ,\n",
    "            #tunewriter= ,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-mwI8DU6x-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5829ab1a7438afd0eb3e39a540a9bafca59bf334debab56f2c37d99237ff203a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
