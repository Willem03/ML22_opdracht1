{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0, \"../..\")\n",
    "\n",
    "from typing import Callable, Protocol, Dict, Optional, Iterator, List, Tuple\n",
    "\n",
    "import gin\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "#from src.data import make_dataset\n",
    "#from src.models import metrics\n",
    "#from src.models import train_model # om de functie train_loop binnen te halen\n",
    "\n",
    "# ------------------------------------------------------------------------------- #\n",
    "## Alle imports benodigd voor de functie train_loop uit train_model.py \n",
    "\n",
    "import tensorflow as tf  # noqa: F401\n",
    "\n",
    "# needed to make summarywriter load without error\n",
    "from loguru import logger\n",
    "from numpy import Inf\n",
    "from ray import tune\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from src.models.metrics import Metric\n",
    "#from src.typehinting import GenericModel\n",
    "#from src.data import data_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## benodigde functie uitmake_dataset.py\n",
    "\n",
    "#@gin.configurable\n",
    "def get_MNIST(  # noqa: N802\n",
    "    data_dir: Path, batch_size: int\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benodigde funties uit metrics.py\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "class Metric:\n",
    "    def __repr__(self) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, y: Tensor, yhat: Tensor) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Accuracy(Metric):\n",
    "    def __repr__(self) -> str:\n",
    "        return \"Accuracy\"\n",
    "\n",
    "    def __call__(self, y: Tensor, yhat: Tensor) -> Tensor:\n",
    "        return (yhat.argmax(dim=1) == y).sum() / len(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericModel(Protocol):\n",
    "    train: Callable\n",
    "    eval: Callable\n",
    "    parameters: Callable\n",
    "\n",
    "    def __call__(self, *args, **kwargs) -> torch.Tensor:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_add_timestamp(log_dir: Optional[Path] = None) -> Path:\n",
    "    if log_dir is None:\n",
    "        log_dir = Path(\".\")\n",
    "    log_dir = Path(log_dir)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    log_dir = log_dir / timestamp\n",
    "    logger.info(f\"Logging to {log_dir}\")\n",
    "    if not log_dir.exists():\n",
    "        log_dir.mkdir(parents=True)\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definieren functie train_loop\n",
    "\n",
    "#@gin.configurable\n",
    "def trainloop(\n",
    "    epochs: int,\n",
    "    model: GenericModel,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    learning_rate: float,\n",
    "    loss_fn: Callable,\n",
    "    metrics: List[Metric],\n",
    "    train_dataloader: Iterator,\n",
    "    test_dataloader: Iterator,\n",
    "    log_dir: Path,\n",
    "    train_steps: int,\n",
    "    eval_steps: int,\n",
    "    patience: int = 10,\n",
    "    factor: float = 0.9,\n",
    "    tunewriter: bool = False,\n",
    ") -> GenericModel:\n",
    "    \n",
    "    optimizer_: torch.optim.Optimizer = optimizer(\n",
    "        model.parameters(), lr=learning_rate\n",
    "    )  # type: ignore\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_,\n",
    "        factor=factor,\n",
    "        patience=patience,\n",
    "    )\n",
    "\n",
    "    if not tunewriter:\n",
    "        log_dir = data_tools.dir_add_timestamp(log_dir)\n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "        write_gin(log_dir, gin.config_str())\n",
    "\n",
    "        images, _ = next(iter(train_dataloader))\n",
    "        if len(images.shape) == 4:\n",
    "            grid = make_grid(images)\n",
    "            writer.add_image(\"images\", grid)\n",
    "        writer.add_graph(model, images)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = trainbatches(\n",
    "            model, train_dataloader, loss_fn, optimizer_, train_steps\n",
    "        )\n",
    "\n",
    "        metric_dict, test_loss = evalbatches(\n",
    "            model, test_dataloader, loss_fn, metrics, eval_steps\n",
    "        )\n",
    "\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "        if tunewriter:\n",
    "            tune.report(\n",
    "                iterations=epoch,\n",
    "                train_loss=train_loss,\n",
    "                test_loss=test_loss,\n",
    "                **metric_dict,\n",
    "            )\n",
    "        else:\n",
    "            writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "            writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "            for m in metric_dict:\n",
    "                writer.add_scalar(f\"metric/{m}\", metric_dict[m], epoch)\n",
    "            lr = [group[\"lr\"] for group in optimizer_.param_groups][0]\n",
    "            writer.add_scalar(\"learning_rate\", lr, epoch)\n",
    "            metric_scores = [f\"{v:.4f}\" for v in metric_dict.values()]\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch} train {train_loss:.4f} test {test_loss:.4f} metric {metric_scores}\"  # noqa E501\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedConfigFileIncludesAndImports(filename='model.gin', imports=['gin.torch.external_configurables'], includes=[])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin.parse_config_file(\"model.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "#@gin.configurable\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int) -> None:\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(10, 3, 16,16).to(device)\n",
    "print(model)\n",
    "summary(model, input_size=(64, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: GenericModel) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opbouw van het model\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_een(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6272, 3136),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3136, 1568),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1568, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_een                                  [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 32, 14, 14]          --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Flatten: 2-4                      [64, 6272]                --\n",
       "│    └─Linear: 2-5                       [64, 3136]                19,672,128\n",
       "│    └─ReLU: 2-6                         [64, 3136]                --\n",
       "│    └─Linear: 2-7                       [64, 1568]                4,918,816\n",
       "│    └─ReLU: 2-8                         [64, 1568]                --\n",
       "│    └─Linear: 2-9                       [64, 10]                  15,690\n",
       "==========================================================================================\n",
       "Total params: 24,606,954\n",
       "Trainable params: 24,606,954\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.59\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 15.26\n",
       "Params size (MB): 98.43\n",
       "Estimated Total Size (MB): 113.89\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "\n",
    "model = CNN_een(10, 3, 32, 32).to(device)\n",
    "summary(model, input_size=(64, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opbouw van het model\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_twee(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, 288),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(288, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_twee                                 [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 32, 6, 6]            --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
       "│    └─Conv2d: 2-4                       [64, 32, 12, 12]          9,248\n",
       "│    └─ReLU: 2-5                         [64, 32, 12, 12]          --\n",
       "│    └─MaxPool2d: 2-6                    [64, 32, 6, 6]            --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Flatten: 2-7                      [64, 1152]                --\n",
       "│    └─Linear: 2-8                       [64, 576]                 664,128\n",
       "│    └─ReLU: 2-9                         [64, 576]                 --\n",
       "│    └─Linear: 2-10                      [64, 288]                 166,176\n",
       "│    └─ReLU: 2-11                        [64, 288]                 --\n",
       "│    └─Linear: 2-12                      [64, 10]                  2,890\n",
       "==========================================================================================\n",
       "Total params: 842,762\n",
       "Trainable params: 842,762\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 154.61\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 15.65\n",
       "Params size (MB): 3.37\n",
       "Estimated Total Size (MB): 19.22\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "\n",
    "model = CNN_twee(10, 3, 32, 32).to(device)\n",
    "summary(model, input_size=(64, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opbouw van het model\n",
    "\n",
    "#@gin.configurable\n",
    "class CNN_drie(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_drie                                 [64, 10]                  --\n",
       "├─Sequential: 1-1                        [64, 32, 2, 2]            --\n",
       "│    └─Conv2d: 2-1                       [64, 32, 28, 28]          320\n",
       "│    └─ReLU: 2-2                         [64, 32, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-3                    [64, 32, 14, 14]          --\n",
       "│    └─Conv2d: 2-4                       [64, 32, 12, 12]          9,248\n",
       "│    └─ReLU: 2-5                         [64, 32, 12, 12]          --\n",
       "│    └─MaxPool2d: 2-6                    [64, 32, 6, 6]            --\n",
       "│    └─Conv2d: 2-7                       [64, 32, 4, 4]            9,248\n",
       "│    └─ReLU: 2-8                         [64, 32, 4, 4]            --\n",
       "│    └─MaxPool2d: 2-9                    [64, 32, 2, 2]            --\n",
       "├─Sequential: 1-2                        [64, 10]                  --\n",
       "│    └─Flatten: 2-10                     [64, 128]                 --\n",
       "│    └─Linear: 2-11                      [64, 64]                  8,256\n",
       "│    └─ReLU: 2-12                        [64, 64]                  --\n",
       "│    └─Linear: 2-13                      [64, 32]                  2,080\n",
       "│    └─ReLU: 2-14                        [64, 32]                  --\n",
       "│    └─Linear: 2-15                      [64, 10]                  330\n",
       "==========================================================================================\n",
       "Total params: 29,482\n",
       "Trainable params: 29,482\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 111.44\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 15.52\n",
       "Params size (MB): 0.12\n",
       "Estimated Total Size (MB): 15.84\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = aantal classes, b = kernel_size, c = grootte filter 1, d = grootte  filter2\n",
    "\n",
    "model = CNN_drie(10, 3, 32, 32).to(device)\n",
    "summary(model, input_size=(64, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"model.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir =  Path(\"/home/admindme/code/ML22_opdracht1/data/raw/FashionMNIST\")\n",
    "train_dataloader, test_dataloader = get_MNIST(datadir, 64)\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'GenericModel' has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m CNN_een\n\u001b[0;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m trainloop(\n\u001b[1;32m      4\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m             model\u001b[39m=\u001b[39;49mGenericModel,\n\u001b[1;32m      6\u001b[0m             optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m      7\u001b[0m             learning_rate\u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m             loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m      9\u001b[0m             metrics\u001b[39m=\u001b[39;49m[accuracy],\n\u001b[1;32m     10\u001b[0m             train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     11\u001b[0m             test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m     12\u001b[0m             log_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../../models/test/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m             train_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_dataloader),\n\u001b[1;32m     14\u001b[0m             eval_steps\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m             \u001b[39m#patience= ,\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m             \u001b[39m#factor= ,\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m             \u001b[39m#tunewriter= ,\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[139], line 22\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrainloop\u001b[39m(\n\u001b[1;32m      5\u001b[0m     epochs: \u001b[39mint\u001b[39m,\n\u001b[1;32m      6\u001b[0m     model: GenericModel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     tunewriter: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m GenericModel:\n\u001b[1;32m     21\u001b[0m     optimizer_: torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mOptimizer \u001b[39m=\u001b[39m optimizer(\n\u001b[0;32m---> 22\u001b[0m         model\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39mlearning_rate\n\u001b[1;32m     23\u001b[0m     )  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(\n\u001b[1;32m     26\u001b[0m         optimizer_,\n\u001b[1;32m     27\u001b[0m         factor\u001b[39m=\u001b[39mfactor,\n\u001b[1;32m     28\u001b[0m         patience\u001b[39m=\u001b[39mpatience,\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tunewriter:\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'GenericModel' has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "model = CNN_een\n",
    "\n",
    "model = trainloop(\n",
    "            epochs=3,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            learning_rate= 0.001,\n",
    "            loss_fn=loss_fn,\n",
    "            metrics=[accuracy],\n",
    "            train_dataloader=train_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            log_dir=\"../../models/test/\",\n",
    "            train_steps=len(train_dataloader),\n",
    "            eval_steps=150,\n",
    "            #patience= ,\n",
    "            #factor= ,\n",
    "            #tunewriter= ,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = Accuracy()\n",
    "\n",
    "filters = [8]\n",
    "kernels = [3]\n",
    "lr = 1e-3\n",
    "\n",
    "for filter in filters:\n",
    "    for kernel in kernels:\n",
    "        #gin.bind_parameter(\"trainloop.learning_rate\", lr)\n",
    "        #gin.bind_parameter(\"CNN.kernel_size\", kernel)\n",
    "        \n",
    "        model = CNN()\n",
    "        #model = CNN(\n",
    "        #    num_classes=10,\n",
    "        #    kernel_size=kernel,\n",
    "        #    filter1=filter,\n",
    "        #    filter2=filter*2\n",
    "        #)\n",
    "            \n",
    "        model = trainloop(\n",
    "            epochs=3,\n",
    "            model=model,\n",
    "            #optimizer= ,\n",
    "            #learning_rate= ,\n",
    "            #loss_fn: Callable= ,\n",
    "            metrics=[accuracy],\n",
    "            train_dataloader=train_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            #log_dir= ,\n",
    "            train_steps=len(train_dataloader),\n",
    "            eval_steps=150,\n",
    "            #patience= ,\n",
    "            #factor= ,\n",
    "            #tunewriter= ,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.remove('../..')\n",
    "sys.path.remove('/home/admindme/code/ML22_opdracht1/notebooks')\n",
    "sys.path.insert(0, '/home/admindme/code/ML22_opdracht1/src')\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "# Changing the CWD\n",
    "os.chdir('../src')\n",
    "#os.chdir('../notebooks')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-mwI8DU6x-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5829ab1a7438afd0eb3e39a540a9bafca59bf334debab56f2c37d99237ff203a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
