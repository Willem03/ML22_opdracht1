{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:15:15.245965: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-23 15:15:16.213809: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-23 15:15:16.213906: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-23 15:15:16.213917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#sys.path.insert(0, \"../..\")\n",
    "\n",
    "from typing import Callable, Protocol, Dict, Optional, Iterator, List, Tuple\n",
    "\n",
    "import gin\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# ------------------------------------------------------------------------------- #\n",
    "## Alle imports benodigd voor de functie train_loop uit train_model.py \n",
    "\n",
    "import tensorflow as tf  # noqa: F401\n",
    "\n",
    "# needed to make summarywriter load without error\n",
    "from loguru import logger\n",
    "from numpy import Inf\n",
    "from ray import tune\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## benodigde functie uitmake_dataset.py\n",
    "\n",
    "@gin.configurable\n",
    "def get_MNIST(  # noqa: N802\n",
    "    data_dir: Path, batch_size: int\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=data_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benodigde funties uit metrics.py\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "class Metric:\n",
    "    def __repr__(self) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, y: Tensor, yhat: Tensor) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Accuracy(Metric):\n",
    "    def __repr__(self) -> str:\n",
    "        return \"Accuracy\"\n",
    "\n",
    "    def __call__(self, y: Tensor, yhat: Tensor) -> Tensor:\n",
    "        return (yhat.argmax(dim=1) == y).sum() / len(yhat)\n",
    "\n",
    "class GenericModel(Protocol):\n",
    "    train: Callable\n",
    "    eval: Callable\n",
    "    parameters: Callable\n",
    "\n",
    "    def __call__(self, *args, **kwargs) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "\n",
    "def count_parameters(model: GenericModel) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "## uit data_tools.py\n",
    "def dir_add_timestamp(log_dir: Optional[Path] = None) -> Path:\n",
    "    if log_dir is None:\n",
    "        log_dir = Path(\".\")\n",
    "    log_dir = Path(log_dir)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    log_dir = log_dir / timestamp\n",
    "    logger.info(f\"Logging to {log_dir}\")\n",
    "    if not log_dir.exists():\n",
    "        log_dir.mkdir(parents=True)\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definieren functie train_loop\n",
    "\n",
    "@gin.configurable\n",
    "def trainloop(\n",
    "    epochs: int,\n",
    "    model: GenericModel,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    learning_rate: float,\n",
    "    loss_fn: Callable,\n",
    "    metrics: List[Metric],\n",
    "    train_dataloader: Iterator,\n",
    "    test_dataloader: Iterator,\n",
    "    log_dir: Path,\n",
    "    train_steps: int,\n",
    "    eval_steps: int,\n",
    "    patience: int = 10,\n",
    "    factor: float = 0.9,\n",
    "    tunewriter: bool = False,\n",
    ") -> GenericModel:\n",
    "    \n",
    "    optimizer_: torch.optim.Optimizer = optimizer(\n",
    "        model.parameters(), lr=learning_rate\n",
    "    )  # type: ignore\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_,\n",
    "        factor=factor,\n",
    "        patience=patience,\n",
    "    )\n",
    "\n",
    "    if not tunewriter:\n",
    "        log_dir = dir_add_timestamp(log_dir)\n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "        #write_gin(log_dir, gin.config_str())\n",
    "\n",
    "        images, _ = next(iter(train_dataloader))\n",
    "        if len(images.shape) == 4:\n",
    "            grid = make_grid(images)\n",
    "            writer.add_image(\"images\", grid)\n",
    "        writer.add_graph(model, images)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = trainbatches(\n",
    "            model, train_dataloader, loss_fn, optimizer_, train_steps\n",
    "        )\n",
    "\n",
    "        metric_dict, test_loss = evalbatches(\n",
    "            model, test_dataloader, loss_fn, metrics, eval_steps\n",
    "        )\n",
    "\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "        if tunewriter:\n",
    "            tune.report(\n",
    "                iterations=epoch,\n",
    "                train_loss=train_loss,\n",
    "                test_loss=test_loss,\n",
    "                **metric_dict,\n",
    "            )\n",
    "        else:\n",
    "            writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "            writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "            for m in metric_dict:\n",
    "                writer.add_scalar(f\"metric/{m}\", metric_dict[m], epoch)\n",
    "            lr = [group[\"lr\"] for group in optimizer_.param_groups][0]\n",
    "            writer.add_scalar(\"learning_rate\", lr, epoch)\n",
    "            metric_scores = [f\"{v:.4f}\" for v in metric_dict.values()]\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch} train {train_loss:.4f} test {test_loss:.4f} metric {metric_scores}\"  # noqa E501\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uit train_model.py\n",
    "\n",
    "def trainbatches(\n",
    "    model: GenericModel,\n",
    "    traindatastreamer: Iterator,\n",
    "    loss_fn: Callable,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_steps: int,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    train_loss: float = 0.0\n",
    "    for _ in tqdm(range(train_steps)):\n",
    "        x, y = next(iter(traindatastreamer))\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.detach().numpy()\n",
    "    train_loss /= train_steps\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "## uit train_model.py\n",
    "def evalbatches(\n",
    "    model: GenericModel,\n",
    "    testdatastreamer: Iterator,\n",
    "    loss_fn: Callable,\n",
    "    metrics: List[Metric],\n",
    "    eval_steps: int,\n",
    ") -> Tuple[Dict[str, float], float]:\n",
    "    model.eval()\n",
    "    test_loss: float = 0.0\n",
    "    metric_dict: Dict[str, float] = {}\n",
    "    for _ in range(eval_steps):\n",
    "        x, y = next(iter(testdatastreamer))\n",
    "        yhat = model(x)\n",
    "        test_loss += loss_fn(yhat, y).detach().numpy()\n",
    "        for m in metrics:\n",
    "            metric_dict[str(m)] = (\n",
    "                metric_dict.get(str(m), 0.0) + m(y, yhat).detach().numpy()\n",
    "            )\n",
    "\n",
    "    test_loss /= eval_steps\n",
    "    for key in metric_dict:\n",
    "        metric_dict[str(key)] = metric_dict[str(key)] / eval_steps\n",
    "    return metric_dict, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 1: CNN_een met een convolutional layer & drie linear layers\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_1_3(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6272, 3136),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3136, 1568),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1568, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.2: CNN_twee met twee convolutional layers & twee linear layers\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_2_2(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.2.16.32: CNN_twee met twee convolutional layers & twee linear layers & 16-32 filters\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_2_2_16_32(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.2.32.64: CNN_twee met twee convolutional layers & twee linear layers & 32-64 filters\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_2_2_32_64(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2304, 1152),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1152, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.2.64.128: CNN_twee met twee convolutional layers & twee linear layers & 64-128 filters\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_2_2_64_128(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4608, 2304),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2304, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.2.128.256: CNN_twee met twee convolutional layers & twee linear layers & 128-256 filters\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_2_2_128_256(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 4608),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4608, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.3: CNN_twee met twee convolutional layers en drie linear layers\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_2_3(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, 288),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(288, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.3.16.32: CNN_twee met twee convolutional layers en drie linear layers\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_2_3_16_32(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, 288),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(288, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.3.32.64: CNN_twee met twee convolutional layers en drie linear layers\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_2_3_32_64(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2304, 1152),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2.4: CNN_twee met twee convolutional layers & vier linear layers\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_2_4(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 576),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(576, 288),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(288, 144),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(144, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3.2: CNN_drie met twee convolutional layers & twee linear layers\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_3_2(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3.3: CNN_drie met drie convolutional layers\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_3_3(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3.4: CNN_drie met drie convolutional layers & vier linear layers\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_3_4(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3.4.64.128: CNN_twee met twee convolutional layers & twee linear layers & 64-128 filters\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_3_4_32_64(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2304, 1152),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1152, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3.4.64.128: CNN_twee met twee convolutional layers & twee linear layers & 64-128 filters\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_3_4_64_128(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4608, 2304),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2304, 1152),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1152, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3.4.128.256: CNN_twee met twee convolutional layers & twee linear layers & 64-128 filters\n",
    "\n",
    "@gin.configurable\n",
    "class CNN_3_4_128_256(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes: int, kernel_size: int, filter1: int, filter2: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=kernel_size, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 4608),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4608, 2304),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2304, 1152),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1152, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedConfigFileIncludesAndImports(filename='model.gin', imports=['gin.torch.external_configurables'], includes=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin.parse_config_file(\"model.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary(model))\n",
    "print(gin.config_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir =  Path(\"/home/admindme/code/ML22_opdracht1/data/raw/FashionMNIST\")\n",
    "train_dataloader, test_dataloader = get_MNIST(datadir, 64)\n",
    "len(train_dataloader), len(test_dataloader)\n",
    "accuracy = Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:51:35.289 | INFO     | __main__:dir_add_timestamp:39 - Logging to /home/admindme/code/ML22_opdracht1/models/test/20221223-1551\n",
      "100%|██████████| 938/938 [03:52<00:00,  4.04it/s]\n",
      "2022-12-23 15:55:32.359 | INFO     | __main__:trainloop:68 - Epoch 0 train 43.8874 test 2.3037 metric ['0.1069']\n",
      "100%|██████████| 938/938 [05:02<00:00,  3.10it/s]\n",
      "2022-12-23 16:00:39.257 | INFO     | __main__:trainloop:68 - Epoch 1 train 2.3066 test 2.3079 metric ['0.0950']\n",
      "100%|██████████| 938/938 [05:02<00:00,  3.10it/s]\n",
      "2022-12-23 16:05:46.406 | INFO     | __main__:trainloop:68 - Epoch 2 train 2.3071 test 2.3080 metric ['0.0979']\n",
      "100%|██████████| 3/3 [14:10<00:00, 283.63s/it]\n"
     ]
    }
   ],
   "source": [
    "## Stap 1 \n",
    "model = CNN_1_3().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:37:20.023 | INFO     | __main__:dir_add_timestamp:39 - Logging to /home/admindme/code/ML22_opdracht1/models/test/20221223-1537\n",
      "100%|██████████| 938/938 [00:28<00:00, 32.52it/s]\n",
      "2022-12-23 15:37:51.203 | INFO     | __main__:trainloop:68 - Epoch 0 train 2.5855 test 2.3057 metric ['0.1016']\n",
      "100%|██████████| 938/938 [00:31<00:00, 29.76it/s]\n",
      "2022-12-23 15:38:24.963 | INFO     | __main__:trainloop:68 - Epoch 1 train 2.3072 test 2.3051 metric ['0.0990']\n",
      "100%|██████████| 938/938 [00:31<00:00, 30.20it/s]\n",
      "2022-12-23 15:38:58.191 | INFO     | __main__:trainloop:68 - Epoch 2 train 11.2988 test 2.3144 metric ['0.0973']\n",
      "100%|██████████| 3/3 [01:38<00:00, 32.67s/it]\n"
     ]
    }
   ],
   "source": [
    "## Stap 1 \n",
    "model = CNN_2_3().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stap 1 \n",
    "model = CNN_3_3().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:35:18.307 | INFO     | __main__:dir_add_timestamp:39 - Logging to /home/admindme/code/ML22_opdracht1/models/test/20221223-1535\n",
      "100%|██████████| 938/938 [00:26<00:00, 34.82it/s]\n",
      "2022-12-23 15:35:47.489 | INFO     | __main__:trainloop:68 - Epoch 0 train 0.8262 test 0.6119 metric ['0.7674']\n",
      "100%|██████████| 938/938 [00:28<00:00, 32.70it/s]\n",
      "2022-12-23 15:36:18.307 | INFO     | __main__:trainloop:68 - Epoch 1 train 0.5509 test 0.5754 metric ['0.7936']\n",
      "100%|██████████| 938/938 [00:29<00:00, 32.28it/s]\n",
      "2022-12-23 15:36:49.404 | INFO     | __main__:trainloop:68 - Epoch 2 train 0.5486 test 0.5939 metric ['0.7932']\n",
      "100%|██████████| 3/3 [01:30<00:00, 30.31s/it]\n"
     ]
    }
   ],
   "source": [
    "## Stap 2 \n",
    "model = CNN_2_2().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:58.316 | INFO     | __main__:dir_add_timestamp:39 - Logging to /home/admindme/code/ML22_opdracht1/models/test/20221223-1538\n",
      "100%|██████████| 938/938 [00:29<00:00, 31.87it/s]\n",
      "2022-12-23 15:39:29.986 | INFO     | __main__:trainloop:68 - Epoch 0 train 3.0085 test 2.3056 metric ['0.1031']\n",
      "100%|██████████| 938/938 [00:31<00:00, 29.38it/s]\n",
      "2022-12-23 15:40:03.943 | INFO     | __main__:trainloop:68 - Epoch 1 train 2.3072 test 2.3043 metric ['0.0973']\n",
      "100%|██████████| 938/938 [00:31<00:00, 29.50it/s]\n",
      "2022-12-23 15:40:37.812 | INFO     | __main__:trainloop:68 - Epoch 2 train 2.3071 test 2.3078 metric ['0.1023']\n",
      "100%|██████████| 3/3 [01:39<00:00, 33.11s/it]\n"
     ]
    }
   ],
   "source": [
    "## Stap 2\n",
    "model = CNN_2_4().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:40:37.923 | INFO     | __main__:dir_add_timestamp:39 - Logging to /home/admindme/code/ML22_opdracht1/models/test/20221223-1540\n",
      "100%|██████████| 938/938 [00:25<00:00, 36.56it/s]\n",
      "2022-12-23 15:41:05.749 | INFO     | __main__:trainloop:68 - Epoch 0 train 0.8298 test 0.7018 metric ['0.7391']\n",
      "100%|██████████| 938/938 [00:25<00:00, 36.91it/s]\n",
      "2022-12-23 15:41:33.243 | INFO     | __main__:trainloop:68 - Epoch 1 train 0.6579 test 0.6638 metric ['0.7675']\n",
      "100%|██████████| 938/938 [00:25<00:00, 36.72it/s]\n",
      "2022-12-23 15:42:00.815 | INFO     | __main__:trainloop:68 - Epoch 2 train 0.6492 test 0.6709 metric ['0.7474']\n",
      "100%|██████████| 3/3 [01:22<00:00, 27.58s/it]\n"
     ]
    }
   ],
   "source": [
    "## Stap 2\n",
    "model = CNN_3_2().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:43:23.387 | INFO     | __main__:dir_add_timestamp:39 - Logging to /home/admindme/code/ML22_opdracht1/models/test/20221223-1543\n",
      "100%|██████████| 938/938 [00:25<00:00, 37.36it/s]\n",
      "2022-12-23 15:43:50.707 | INFO     | __main__:trainloop:68 - Epoch 0 train 2.3202 test 2.3060 metric ['0.0968']\n",
      "100%|██████████| 938/938 [00:25<00:00, 36.57it/s]\n",
      "2022-12-23 15:44:18.445 | INFO     | __main__:trainloop:68 - Epoch 1 train 2.3070 test 2.3090 metric ['0.0979']\n",
      "100%|██████████| 938/938 [00:25<00:00, 36.82it/s]\n",
      "2022-12-23 15:44:45.963 | INFO     | __main__:trainloop:68 - Epoch 2 train 2.3072 test 2.3072 metric ['0.0982']\n",
      "100%|██████████| 3/3 [01:22<00:00, 27.47s/it]\n"
     ]
    }
   ],
   "source": [
    "## Stap 2\n",
    "model = CNN_3_4().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:42:00.902 | INFO     | __main__:dir_add_timestamp:39 - Logging to /home/admindme/code/ML22_opdracht1/models/test/20221223-1542\n",
      "100%|██████████| 938/938 [00:25<00:00, 37.01it/s]\n",
      "2022-12-23 15:42:28.570 | INFO     | __main__:trainloop:68 - Epoch 0 train 0.8986 test 0.7151 metric ['0.7539']\n",
      "100%|██████████| 938/938 [00:25<00:00, 37.17it/s]\n",
      "2022-12-23 15:42:55.920 | INFO     | __main__:trainloop:68 - Epoch 1 train 0.7129 test 0.7403 metric ['0.7481']\n",
      "100%|██████████| 938/938 [00:25<00:00, 37.19it/s]\n",
      "2022-12-23 15:43:23.275 | INFO     | __main__:trainloop:68 - Epoch 2 train 0.6766 test 0.7022 metric ['0.7561']\n",
      "100%|██████████| 3/3 [01:22<00:00, 27.40s/it]\n"
     ]
    }
   ],
   "source": [
    "## Stap 3\n",
    "model = CNN_2_2_16_32().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stap 3\n",
    "model = CNN_2_2_32_64().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stap 3\n",
    "model = CNN_2_3_16_32().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stap 3\n",
    "model = CNN_2_3_32_64().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stap 3 Nieuw\n",
    "model = CNN_2_2_64_128().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stap 3 Nieuw\n",
    "model = CNN_2_2_128_256().to(device)\n",
    "\n",
    "model = trainloop(\n",
    "                model=model,\n",
    "                metrics=[accuracy],\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                train_steps=len(train_dataloader),\n",
    "                eval_steps=150,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-mwI8DU6x-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5829ab1a7438afd0eb3e39a540a9bafca59bf334debab56f2c37d99237ff203a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
